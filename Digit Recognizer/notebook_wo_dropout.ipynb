{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recogniser\n",
    "In this notebook , I have used the famous **mnist dataset** of grayscale digit images to make a **CNN** model to recognize digits .\n",
    "- This is the first notebook of series .In the this notebook , I will train a CNN model without dropout ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist \n",
    "from keras.utils import np_utils\n",
    "# the data, shuffled and split between train and test sets \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for beginners:\n",
    "- output_dim is the length of the of output of our CNN (10 for ten digits)\n",
    "- **batch_size** is the number of images that will be used per batch in one epoch of our CNN model.You can play with this number on your local machine.\n",
    "- After processing every batch ,weigths of the mmodel are updated.\n",
    "- Number of batches per epoch = Total number of images / batch_size\n",
    "- **nb_epochs** is the number of itterations for which whole set of images will be processed in the form of batches.\n",
    "- I have taken a quite high number(50) beacause I was playing with the model on GPU.\n",
    "- If you are using a CPU , it might take some time to fit.(You can use the weights that I have provided in the repository)\n",
    "- 10 epochs is sufficient for your purpose if you are using cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = nb_classes = 10 \n",
    "batch_size = 512 \n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and analysing\n",
    "- Analysing our data and preparing it for the input format of our \n",
    "- Addded an extra channel dimension to the X and one hot encoded the Y.\n",
    "- Normalized the data from (0-255) to (0.0 - 1.0 ) by dividing by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28)\n",
      "X_train shape:  (60000, 28, 28, 1)\n",
      "Y_train shape:  (60000, 10)\n",
      "X_test shape:  (10000, 28, 28, 1)\n",
      "Y_test shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "input_dim = 784 #28*28*1\n",
    "print('x_train shape: ',x_train.shape)\n",
    "X_train = x_train.reshape(60000, 28,28,1) \n",
    "X_test = x_test.reshape(10000, 28,28,1) \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes) \n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print('X_train shape: ',X_train.shape)\n",
    "print('Y_train shape: ',Y_train.shape)\n",
    "print('X_test shape: ',X_test.shape)\n",
    "print('Y_test shape: ',Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation,Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               1024250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                12550     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 1,425,150\n",
      "Trainable params: 1,425,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the best model is very important \n",
    "- Criteria should be based on validation data rather than train data\n",
    "- This saves your model checkpoints every time ,when there is a improvement in validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# without(wo) dropout\n",
    "checkpoint_path = \"cp_mnist_wo_dropout.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the best model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_accuracy', \n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, Training the model\n",
    "**Note:** This might take some time (more than 1hr) if you are using tensorflow-cpu. Although you can load weights that I provided if you don't want to waste time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 46s 764us/step - loss: 0.5167 - accuracy: 0.8354 - val_loss: 0.1171 - val_accuracy: 0.9635\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96350, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 23s 384us/step - loss: 0.0726 - accuracy: 0.9773 - val_loss: 0.0908 - val_accuracy: 0.9714\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.96350 to 0.97140, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.0464 - accuracy: 0.9851 - val_loss: 0.0318 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.97140 to 0.98930, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 24s 408us/step - loss: 0.0327 - accuracy: 0.9898 - val_loss: 0.0349 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.98930\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 24s 396us/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.0449 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.98930\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 23s 387us/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0250 - val_accuracy: 0.9921: 8s - ETA: 1s - loss: 0.0187 - accura - ETA: 0s - loss: 0.0185 - accuracy\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.98930 to 0.99210, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 23s 390us/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0327 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.99210\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 23s 391us/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1216 - val_accuracy: 0.9692: 0.0100 -  - ETA: 2s - loss: 0.0101 - accura - ETA: 1s - loss: 0.0102 - \n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99210\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0686 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99210\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 24s 396us/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0288 - val_accuracy: 0.99190.0070 - accuracy\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99210\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 24s 394us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0387 - val_accuracy: 0.99060040 - accuracy: 0.99\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.99210\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0333 - val_accuracy: 0.9914\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99210\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 25s 419us/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0299 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.99210 to 0.99260, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 33s 549us/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0288 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.99260 to 0.99290, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 30s 506us/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.0463 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99290\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 26s 434us/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0370 - val_accuracy: 0.9912\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99290\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 25s 421us/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0294 - val_accuracy: 0.9930\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.99290 to 0.99300, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 7.4110e-04 - accuracy: 0.9998 - val_loss: 0.0499 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99300\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0436 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99300\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 23s 389us/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0461 - val_accuracy: 0.9898 14s - loss: 0 - ETA: 5s - loss: 0.0016 - accuracy: 0.99 - ETA: 5s - loss: 0.0016 - \n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99300\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0359 - val_accuracy: 0.9928\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.99300\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 24s 392us/step - loss: 8.5751e-04 - accuracy: 0.9998 - val_loss: 0.0341 - val_accuracy: 0.9928\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.99300\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 25s 413us/step - loss: 7.0333e-05 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.99300\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 24s 396us/step - loss: 3.4986e-05 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9930\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.99300\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 2.4655e-05 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9931acy: 1.\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.99300 to 0.99310, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 25s 414us/step - loss: 2.0160e-05 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.99310 to 0.99320, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 25s 410us/step - loss: 1.6674e-05 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.99320\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 1.4448e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.99320\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 1.2820e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.99320\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 24s 401us/step - loss: 1.1459e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.99320\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 1.0293e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9931 - loss: 1.0121e-0 - ETA: 2s - loss: 1.0205e-05 - ac - ETA: 0s - loss: 1.0306e-05 - accuracy: 1.00 - ETA: 0s - loss: 1.0411e-05 - accura\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.99320\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 9.3744e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.99320\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 8.5752e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.99320\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 24s 399us/step - loss: 8.0036e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.99320\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 24s 408us/step - loss: 7.4031e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.99320\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 6.8965e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.99320 to 0.99330, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 24s 407us/step - loss: 6.4700e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.99330\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 25s 417us/step - loss: 6.0631e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.99330\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 5.8263e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.99330\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 25s 421us/step - loss: 5.4935e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.99330\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 25s 422us/step - loss: 5.1801e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.99330\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 25s 415us/step - loss: 4.9822e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.99330 to 0.99340, saving model to cp_mnist_wo_dropout.ckpt\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 23s 391us/step - loss: 4.7492e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.99340\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 25s 415us/step - loss: 4.5324e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.99340\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 4.3457e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.99340\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 24s 408us/step - loss: 4.1610e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9934- ETA: 0s - loss: 4.1552e-06 - accuracy: 1.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.99340\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 23s 390us/step - loss: 3.9848e-06 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.99340\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 23s 391us/step - loss: 3.8576e-06 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.99340\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 3.7100e-06 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.99340\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 24s 401us/step - loss: 3.5781e-06 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9934- loss: 3.5930e-06 - accura\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.99340\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model(OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the best saved model\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.04328024726516478\n",
      "Test accuracy: 0.993399977684021\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test,  Y_test, verbose=2)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "- We can see that there is a high overfitting on the training data.\n",
    "- Pretty good accuracy but we can do better.\n",
    "- Play with hyperparameter and let me know what you find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pretrained model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "test_data  = pd.read_csv('test.csv')\n",
    "test = test_data.iloc[:,:].values\n",
    "print(test.shape)\n",
    "test = test.reshape(test.shape[0],28,28,1)\n",
    "print(test.shape)\n",
    "sub1 = model.predict(test)\n",
    "pred = np.argmax(sub1,axis = 1)\n",
    "pd.DataFrame(pred,columns=['Label']).to_csv('submission3.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.04193375406090608\n",
      "Test accuracy: 0.993399977684021\n"
     ]
    }
   ],
   "source": [
    "#Load the best saved model\n",
    "model.load_weights(checkpoint_path)\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(X_test,  Y_test, verbose=2)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)\n",
    "sub2 = model.predict(test)\n",
    "pred = np.argmax(sub2,axis = 1)\n",
    "pd.DataFrame(pred,columns=['Label']).to_csv('submission4.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
